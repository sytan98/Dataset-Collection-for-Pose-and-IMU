{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pytransform3d.transformations as pt\n",
    "import pytransform3d.trajectories as ptr\n",
    "from pytransform3d.camera import check_transform, transform, vectors_to_points, _make_camera_frame, _make_camera_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_camera(ax=None, M=None, cam2world=None, virtual_image_distance=1.0,\n",
    "                sensor_size=(1920, 1080), ax_s=1, strict_check=True,\n",
    "                **kwargs):  # pragma: no cover\n",
    "    \"\"\"Plot camera in world coordinates.\n",
    "\n",
    "    This function is inspired by Blender's camera visualization. It will\n",
    "    show the camera center, a virtual image plane, and the top of the virtual\n",
    "    image plane.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : Matplotlib 3d axis, optional (default: None)\n",
    "        If the axis is None, a new 3d axis will be created.\n",
    "\n",
    "    M : array-like, shape (3, 3)\n",
    "        Intrinsic camera matrix that contains the focal lengths on the diagonal\n",
    "        and the center of the the image in the last column. It does not matter\n",
    "        whether values are given in meters or pixels as long as the unit is the\n",
    "        same as for the sensor size.\n",
    "\n",
    "    cam2world : array-like, shape (4, 4), optional (default: I)\n",
    "        Transformation matrix of camera in world frame. We assume that the\n",
    "        position is given in meters.\n",
    "\n",
    "    virtual_image_distance : float, optional (default: 1)\n",
    "        Distance from pinhole to virtual image plane that will be displayed.\n",
    "        We assume that this distance is given in meters. The unit has to be\n",
    "        consistent with the unit of the position in cam2world.\n",
    "\n",
    "    sensor_size : array-like, shape (2,), optional (default: [1920, 1080])\n",
    "        Size of the image sensor: (width, height). It does not matter whether\n",
    "        values are given in meters or pixels as long as the unit is the same as\n",
    "        for the sensor size.\n",
    "\n",
    "    ax_s : float, optional (default: 1)\n",
    "        Scaling of the new matplotlib 3d axis.\n",
    "\n",
    "    strict_check : bool, optional (default: True)\n",
    "        Raise a ValueError if the transformation matrix is not numerically\n",
    "        close enough to a real transformation matrix. Otherwise we print a\n",
    "        warning.\n",
    "\n",
    "    kwargs : dict, optional (default: {})\n",
    "        Additional arguments for the plotting functions, e.g. alpha.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : Matplotlib 3d axis\n",
    "        New or old axis\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input is not valid\n",
    "    \"\"\"\n",
    "\n",
    "    cam2world = check_transform(cam2world, strict_check=strict_check)\n",
    "\n",
    "    camera_center_in_world = cam2world[:3, 3]\n",
    "    focal_length = np.mean(np.diag(M[:2, :2]))\n",
    "    # X points to right, y points down, z points forward\n",
    "    sensor_corners_in_cam = np.array([\n",
    "        [focal_length, 0, 0], #Top left\n",
    "        [focal_length, 0, sensor_size[1]], #Top right\n",
    "        [focal_length, sensor_size[0], sensor_size[1]], #Bottom right\n",
    "        [focal_length, sensor_size[0], 0], #Bottom left\n",
    "    ])\n",
    "    sensor_corners_in_cam[:, 1] -= M[0, 2]\n",
    "    sensor_corners_in_cam[:, 2] -= M[1, 2]\n",
    "    sensor_corners_in_world = transform(\n",
    "        cam2world, vectors_to_points(sensor_corners_in_cam))[:, :3]\n",
    "    virtual_image_corners = (\n",
    "        virtual_image_distance / focal_length *\n",
    "        (sensor_corners_in_world - camera_center_in_world[np.newaxis]) +\n",
    "        camera_center_in_world[np.newaxis])\n",
    "\n",
    "    if \"c\" in kwargs:\n",
    "        color = kwargs.pop(\"c\")\n",
    "    elif \"color\" in kwargs:\n",
    "        color = kwargs.pop(\"color\")\n",
    "    else:\n",
    "        color = \"k\"\n",
    "\n",
    "    _make_camera_frame(\n",
    "        ax, virtual_image_corners, camera_center_in_world, color, **kwargs)\n",
    "    _make_camera_top(ax, virtual_image_corners, color, **kwargs)\n",
    "    ax.scatter(camera_center_in_world[0], camera_center_in_world[1],\n",
    "               camera_center_in_world[2], color=color, **kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from itertools import cycle\n",
    "\n",
    "def calc_quat_angle_error_single(label, pred):\n",
    "    q1 = np.array(pred / np.linalg.norm(pred))\n",
    "    q2 = np.array(label / np.linalg.norm(label))\n",
    "    d = np.abs(np.sum(np.multiply(q1,q2))) # Here we have abs()\n",
    "\n",
    "    d = np.clip(d, a_min=-1, a_max=1)\n",
    "    error = 2 * np.degrees(np.arccos(d))\n",
    "    return error\n",
    "\n",
    "def plot_pred_and_targ(pred_poses, targ_poses, x_lim=[0, -10], y_lim=[-10, 0], z_lim=[-1, -5], start=0, end=50, step=10):\n",
    "    sensor_size = np.array([0.036, 0.024])\n",
    "    intrinsic_matrix = np.array([\n",
    "        [0.05, 0, sensor_size[0] / 2.0],\n",
    "        [0, 0.05, sensor_size[1] / 2.0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    virtual_image_distance = 1\n",
    "    ax = plt.axes(projection= '3d')\n",
    "    colors = cycle(\"rgbcm\")\n",
    "    ax = ptr.plot_trajectory(ax, P=targ_poses[start:end:step], s=0.1,show_direction=False, lw=2, n_frames=10, c='k')\n",
    "    for targ_pose, c in zip(targ_poses[start:end:step], colors):\n",
    "        x,y,z,qw,qx,qy,qz = targ_pose\n",
    "        cam2world = pt.transform_from_pq([x,y,z,qw,qx,qy,qz])\n",
    "        # default parameters of a camera in Blender\n",
    "        plot_camera(ax, cam2world=cam2world, M=intrinsic_matrix, sensor_size=sensor_size,\n",
    "            virtual_image_distance=virtual_image_distance, c=c)\n",
    "\n",
    "    colors = cycle(\"rgbcm\")\n",
    "    ax = ptr.plot_trajectory(ax, P=pred_poses[start:end:step], s=0.1,show_direction=False, lw=2, n_frames=10, c='y')\n",
    "    for pred_pose, c in zip(pred_poses[start:end:step], colors):\n",
    "        x,y,z,qw,qx,qy,qz = pred_pose\n",
    "        cam2world = pt.transform_from_pq([x,y,z,qw,qx,qy,qz])\n",
    "        # default parameters of a camera in Blender\n",
    "        plot_camera(ax, cam2world=cam2world, M=intrinsic_matrix, sensor_size=sensor_size,\n",
    "            virtual_image_distance=virtual_image_distance, c=c)\n",
    "    # calculate losses\n",
    "    t_criterion = lambda t_pred, t_gt: np.linalg.norm(t_pred - t_gt)\n",
    "    q_criterion = calc_quat_angle_error_single\n",
    "    t_loss = np.asarray([t_criterion(p, t) for p, t in zip(pred_poses[start:end:step, :3],\n",
    "                                                           targ_poses[start:end:step, :3])])\n",
    "    q_loss = np.asarray([q_criterion(p, t) for p, t in zip(pred_poses[start:end:step, 3:],\n",
    "                                                           targ_poses[start:end:step, 3:])])\n",
    "\n",
    "    print('Error in translation: median {:3.2f} m,  mean {:3.2f} m\\n'\n",
    "            'Error in rotation: median {:3.2f} degrees, mean {:3.2f} degree'.format(np.median(t_loss), np.mean(t_loss),\n",
    "                                                                                    np.median(q_loss), np.mean(q_loss)))\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "    ax.set_zlim(z_lim)\n",
    "    ax.set_xlabel('x (m)')\n",
    "    ax.set_ylabel('y (m)')\n",
    "    ax.set_zlabel('z (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/AirSim_building_new_mapnet_noise_none_baseline.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "targ_poses = data['targ_poses']\n",
    "pred_poses = data['pred_poses']\n",
    "plt.figure()\n",
    "# plot_pred_and_targ(pred_poses, targ_poses, [-2, -8], [-10, -2], [-1, -4], 100, 140, 10)\n",
    "plot_pred_and_targ(pred_poses, targ_poses)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/AirSim_building_new_mapnet_noise_none_imu_0_5.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "targ_poses = data['targ_poses']\n",
    "pred_poses = data['pred_poses']\n",
    "plt.figure()\n",
    "# plot_pred_and_targ(pred_poses, targ_poses, [-2, -8], [-10, -2], [-1, -4], 100, 140, 10)\n",
    "plot_pred_and_targ(pred_poses, targ_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/AirSim_building_new_mapnet_noise_v1_baseline.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "targ_poses = data['targ_poses']\n",
    "pred_poses = data['pred_poses']\n",
    "plt.figure()\n",
    "# plot_pred_and_targ(pred_poses, targ_poses, [-2, -8], [-10, -2], [-1, -4], 100, 140, 10)\n",
    "plot_pred_and_targ(pred_poses, targ_poses)\n",
    "# plt.legend([\"Target\", \"Prediction\"])\n",
    "ax = plt.gca()\n",
    "leg = ax.legend([\"Target\", \"Prediction\"])\n",
    "leg.legendHandles[0].set_color('k')\n",
    "leg.legendHandles[1].set_color('y')\n",
    "plt.title(\"Baseline trained on Noisy_v1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/AirSim_building_new_mapnet_noise_v1_imu_0_5.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "targ_poses = data['targ_poses']\n",
    "pred_poses = data['pred_poses']\n",
    "plt.figure()\n",
    "# plot_pred_and_targ(pred_poses, targ_poses, [-2, -8], [-10, -2], [-1, -4], 100, 140, 10)\n",
    "plot_pred_and_targ(pred_poses, targ_poses)\n",
    "ax = plt.gca()\n",
    "leg = ax.legend([\"Target\", \"Prediction\"])\n",
    "leg.legendHandles[0].set_color('k')\n",
    "leg.legendHandles[1].set_color('y')\n",
    "plt.title(\"Weighted loss function model (alpha = 0.5) trained on Noisy_v1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('imu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e114fece839044a8054c0aaa3bdbd75b217de5939a76fc671a63ad8057104e17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
