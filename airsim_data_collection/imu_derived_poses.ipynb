{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rowan\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy import integrate\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f'D:/Imperial/FYP/captured_data/airsim_drone_mode/building_new/train/airsim_rec.txt', sep=\"\\t\")\n",
    "test_data = pd.read_csv(f'D:/Imperial/FYP/captured_data/airsim_drone_mode/building_new/val/airsim_rec.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.figure()\n",
    "ax = plt.axes(projection= '3d')\n",
    "ax.plot3D(train_data[\"POS_X\"], train_data[\"POS_Y\"], train_data[\"POS_Z\"], label = \"AirSim Ground Truth Train Poses\", color = 'blue')\n",
    "ax.plot3D(test_data[\"POS_X\"], test_data[\"POS_Y\"], test_data[\"POS_Z\"], label = \"AirSim Ground Truth Test Poses\", color = 'red')\n",
    "ax.set_zlim([-2, -5])\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "ax.set_zlabel(\"z (m)\")\n",
    "ax.set_title(\"AirSim Training and Test Trajectories\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from utils import calc_quat_angle_error_single, calc_rel_orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_data \n",
    "plt.figure()\n",
    "plt.hist(dataset[\"POS_X\"], label=\"POS_X\", alpha=0.5)\n",
    "plt.hist(dataset[\"POS_Y\"], label=\"POS_Y\", alpha=0.5)\n",
    "plt.hist(dataset[\"POS_Z\"], label=\"POS_Z\", alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Position Coordinates (m)\")\n",
    "plt.title('Distribution of Test Set Translations ' + r'$\\bf{x}_c$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(dataset[\"Q_W\"], label=\"Q_W\", alpha=0.5)\n",
    "plt.hist(dataset[\"Q_X\"], label=\"Q_X\", alpha=0.5)\n",
    "plt.hist(dataset[\"Q_Y\"], label=\"Q_Y\", alpha=0.5)\n",
    "plt.hist(dataset[\"Q_Z\"], label=\"Q_Z\", alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Quaternion Values\")\n",
    "plt.title('Distribution of Test Set Orientations ' + r'$\\bf{q}_c$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for IMU relative pose calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate timestamp, time from start in seconds, and timestep between imu recordings\n",
    "train_data[\"timestamp\"] = pd.to_datetime(train_data[\"timestamp\"], unit='ns')\n",
    "train_data[\"seconds\"] = (train_data[\"timestamp\"] - train_data[\"timestamp\"][0]).dt.total_seconds()\n",
    "train_data[\"prev_timestamp\"] = train_data[\"timestamp\"].shift(1)\n",
    "train_data[\"timestep\"] = ((train_data[\"timestamp\"] - train_data[\"prev_timestamp\"]).dt.total_seconds())\n",
    "\n",
    "\n",
    "# Get previous angular velocity\n",
    "train_data[\"prev_S_ANG_VEL_X\"] = train_data[\"S_ANG_VEL_X\"].shift(1)\n",
    "train_data[\"prev_S_ANG_VEL_Y\"] = train_data[\"S_ANG_VEL_Y\"].shift(1)\n",
    "train_data[\"prev_S_ANG_VEL_Z\"] = train_data[\"S_ANG_VEL_Z\"].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "if mode == 0:\n",
    "    noise_x = 0\n",
    "    noise_y = 0\n",
    "    noise_z = 0\n",
    "elif mode == 1:\n",
    "    noise_x = np.random.normal(0,0.5,len(train_data))\n",
    "    noise_y = np.random.normal(0,0.5,len(train_data))\n",
    "    noise_z = np.random.normal(0,0.1,len(train_data))\n",
    "elif mode == 2:     \n",
    "    noise_x = np.random.normal(0,0.8,len(train_data))\n",
    "    noise_y = np.random.normal(0,0.8,len(train_data))\n",
    "    noise_z = np.random.normal(0,0.2,len(train_data))\n",
    "\n",
    "train_data[\"noisy_POS_X\"] = noise_x + train_data[\"POS_X\"]\n",
    "train_data[\"noisy_POS_Y\"] = noise_y + train_data[\"POS_Y\"]\n",
    "train_data[\"noisy_POS_Z\"] = noise_z + train_data[\"POS_Z\"]\n",
    "\n",
    "train_data[\"noisy_prev_POS_X\"] = train_data[\"noisy_POS_X\"].shift(1)\n",
    "train_data[\"noisy_prev_POS_Y\"] = train_data[\"noisy_POS_Y\"].shift(1)\n",
    "train_data[\"noisy_prev_POS_Z\"] = train_data[\"noisy_POS_Z\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "start=0\n",
    "step = 10\n",
    "ax = plt.axes(projection= '3d')\n",
    "ax.plot3D(train_data[\"noisy_POS_X\"].iloc[start::step], train_data[\"noisy_POS_Y\"].iloc[start::step], train_data[\"noisy_POS_Z\"].iloc[start::step], label = \"Noisy ground truth train poses\", color = 'blue')\n",
    "ax.plot3D(train_data[\"POS_X\"].iloc[start::step], train_data[\"POS_Y\"].iloc[start::step], train_data[\"POS_Z\"].iloc[start::step], label = \"Original ground truth train poses\", color = 'Green')\n",
    "ax.set_zlim([-2, -5])\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "ax.set_zlabel(\"z (m)\")\n",
    "ax.set_title(\"Noisy v2 Training Poses\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "    noise_qw = 0\n",
    "    noise_qx = 0\n",
    "    noise_qy = 0\n",
    "    noise_qz = 0\n",
    "elif mode == 1:\n",
    "    noise_qw = np.random.normal(0,0.03,len(train_data))\n",
    "    noise_qx = np.random.normal(0,0.03,len(train_data))\n",
    "    noise_qy = np.random.normal(0,0.03,len(train_data))\n",
    "    noise_qz = np.random.normal(0,0.03,len(train_data))\n",
    "elif mode == 2:     \n",
    "    noise_qw = np.random.normal(0,0.05,len(train_data))\n",
    "    noise_qx = np.random.normal(0,0.05,len(train_data))\n",
    "    noise_qy = np.random.normal(0,0.05,len(train_data))\n",
    "    noise_qz = np.random.normal(0,0.05,len(train_data))\n",
    "train_data[\"noisy_Q_W\"] = noise_qw + train_data[\"Q_W\"]\n",
    "train_data[\"noisy_Q_X\"] = noise_qx + train_data[\"Q_X\"]\n",
    "train_data[\"noisy_Q_Y\"] = noise_qy + train_data[\"Q_Y\"]\n",
    "train_data[\"noisy_Q_Z\"] = noise_qz + train_data[\"Q_Z\"]\n",
    "\n",
    "# Ensure that noisy quaternions is a valid rotation\n",
    "normalized_q = pd.DataFrame(rowan.normalize(train_data[[\"noisy_Q_W\", \"noisy_Q_X\", \"noisy_Q_Y\", \"noisy_Q_Z\"]]), columns=[\"noisy_Q_W\", \"noisy_Q_X\", \"noisy_Q_Y\", \"noisy_Q_Z\"])\n",
    "train_data[\"noisy_Q_W\"] = normalized_q[\"noisy_Q_W\"]\n",
    "train_data[\"noisy_Q_X\"] = normalized_q[\"noisy_Q_X\"]\n",
    "train_data[\"noisy_Q_Y\"] = normalized_q[\"noisy_Q_Y\"]\n",
    "train_data[\"noisy_Q_Z\"] = normalized_q[\"noisy_Q_Z\"]\n",
    "\n",
    "train_data[\"noisy_prev_Q_W\"] = train_data[\"noisy_Q_W\"].shift(1)\n",
    "train_data[\"noisy_prev_Q_X\"] = train_data[\"noisy_Q_X\"].shift(1)\n",
    "train_data[\"noisy_prev_Q_Y\"] = train_data[\"noisy_Q_Y\"].shift(1)\n",
    "train_data[\"noisy_prev_Q_Z\"] = train_data[\"noisy_Q_Z\"].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Absolute Error after noise injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err =[]\n",
    "for idx, row, in train_data.iterrows():\n",
    "    err.append(np.linalg.norm(np.array(row[[\"noisy_POS_X\", \"noisy_POS_Y\", \"noisy_POS_Z\"]]) - np.array(row[[\"POS_X\", \"POS_Y\", \"POS_Z\"]])))\n",
    "print(f'Translation error {np.median(err)} (median) m, {np.mean(err)} (mean) m')\n",
    "\n",
    "q_err = train_data.apply(lambda row: \n",
    "                        calc_quat_angle_error_single(\n",
    "                            np.hstack([row[\"noisy_Q_W\"], row[\"noisy_Q_X\"], row[\"noisy_Q_Y\"], row[\"noisy_Q_Z\"]]),\n",
    "                            np.hstack([row[\"Q_W\"], row[\"Q_X\"], row[\"Q_Y\"], row[\"Q_Z\"]])\n",
    "                        ), axis=1)\n",
    "print(f'Orientation error {np.median(q_err)} (median) deg, {np.mean(q_err)} (mean) deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert linear acceleration to world coordinate frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ahrs.filters import AngularRate\n",
    "qw = train_data.iloc[0, :].noisy_Q_W\n",
    "qx = train_data.iloc[0, :].noisy_Q_X\n",
    "qy = train_data.iloc[0, :].noisy_Q_Y\n",
    "qz = train_data.iloc[0, :].noisy_Q_Z\n",
    "cur_q = np.array([qw, qx, qy, qz])\n",
    "abs_results = [cur_q]\n",
    "angular_rate = AngularRate()\n",
    "for j in range(1, len(train_data)):\n",
    "    row = train_data.iloc[j, :]\n",
    "    cur_q = angular_rate.update(cur_q, \n",
    "                                np.hstack([row[\"prev_S_ANG_VEL_X\"],\n",
    "                                            row[\"prev_S_ANG_VEL_Y\"], \n",
    "                                            row[\"prev_S_ANG_VEL_Z\"]]),\n",
    "                                'series', \n",
    "                                1,\n",
    "                                row['timestep'])\n",
    "    norm_q = cur_q\n",
    "    if norm_q[0] < 0:\n",
    "        norm_q = -norm_q\n",
    "    abs_results.append(norm_q)\n",
    "imu_q_ahrs = pd.DataFrame(abs_results, columns=[\"pure_imu_Q_W\", \"pure_imu_Q_X\", \"pure_imu_Q_Y\", \"pure_imu_Q_Z\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_q_ahrs.plot()\n",
    "train_data[[\"noisy_Q_W\", \"noisy_Q_X\", \"noisy_Q_Y\", \"noisy_Q_Z\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "check_data = pd.concat([train_data, imu_q_ahrs], axis=1)\n",
    "def convert_body_to_world(row):\n",
    "    body_acc = np.hstack([row[\"S_LIN_ACC_X\"], row[\"S_LIN_ACC_Y\"], row[\"S_LIN_ACC_Z\"]]).astype(float)\n",
    "    r = R.from_quat(np.hstack([row[\"pure_imu_Q_X\"], row[\"pure_imu_Q_Y\"], row[\"pure_imu_Q_Z\"], row[\"pure_imu_Q_W\"]]))\n",
    "    world_acc = r.apply(body_acc)\n",
    "    return world_acc - np.array([0, 0, -9.81])\n",
    "\n",
    "# Convert imu linear acceleration from body frame to world frame\n",
    "check_data[\"S_LIN_ACC_X_world\"] = check_data.apply(lambda row : convert_body_to_world(row)[0], axis = 1)\n",
    "check_data[\"S_LIN_ACC_Y_world\"] = check_data.apply(lambda row : convert_body_to_world(row)[1], axis = 1)\n",
    "check_data[\"S_LIN_ACC_Z_world\"] = check_data.apply(lambda row : convert_body_to_world(row)[2], axis = 1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "t = check_data[\"seconds\"]\n",
    "\n",
    "vel_x = integrate.cumtrapz(check_data[\"S_LIN_ACC_X_world\"], t, initial=0)\n",
    "vel_y = integrate.cumtrapz(check_data[\"S_LIN_ACC_Y_world\"], t, initial=0)\n",
    "vel_z = integrate.cumtrapz(check_data[\"S_LIN_ACC_Z_world\"], t, initial=0) \n",
    "plt.plot(t, vel_x, label = \"velocity_x\")\n",
    "plt.plot(t, signal.detrend(vel_x), label = \"velocity_x_detrended\")\n",
    "plt.plot(t, check_data[\"LIN_VEL_X\"], label = \"gt_velocity_x\")\n",
    "plt.title(\"Velocity integrated from acceleration\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (m/s)\")\n",
    "# plt.xlim([50, 160])\n",
    "# plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(t, integrate.cumtrapz(vel_x, t, initial=0) +  check_data[\"POS_X\"][0], label = \"position_x\")\n",
    "plt.plot(t, integrate.cumtrapz(signal.detrend(vel_x), t, initial=0) + check_data[\"POS_X\"][0], label = \"position_x_from_detrended_velocity\")\n",
    "plt.plot(t,check_data[\"POS_X\"], label = \"gt_position_x\")\n",
    "plt.title(\"Position double integrated from acceleration\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (m)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# plt.plot(t, integrate.cumtrapz(vel_y, t, initial=0) +  check_data[\"POS_Y\"][0], label = \"position_y\")\n",
    "plt.plot(t, integrate.cumtrapz(signal.detrend(vel_y), t, initial=0) + check_data[\"POS_Y\"][0], label = \"position_y_from_detrended_velocity\")\n",
    "plt.plot(t,check_data[\"POS_Y\"], label = \"gt_position_y\")\n",
    "# plt.plot(t, integrate.cumtrapz(vel_x, t, initial=0) +  check_data[\"POS_X\"][0], label = \"pos_x\")\n",
    "# plt.plot(t, integrate.cumtrapz(signal.detrend(vel_x), t, initial=0) + check_data[\"POS_X\"][0], label = \"pos_x_detrended\")\n",
    "# plt.plot(t,check_data[\"POS_X\"], label = \"gt_pos_x\")\n",
    "# plt.plot(t, integrate.cumtrapz(vel_z, t, initial=0) +  check_data[\"POS_Z\"][0], label = \"pos_z\")\n",
    "# plt.plot(t, integrate.cumtrapz(signal.detrend(vel_z), t, initial=0) + check_data[\"POS_Z\"][0], label = \"pos_z_detrended\")\n",
    "# plt.plot(t,check_data[\"POS_Z\"], label = \"gt_pos_z\")\n",
    "plt.title(\"Position double integrated from acceleration\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (m)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, imu_q_ahrs], axis=1)\n",
    "def convert_body_to_world(row):\n",
    "    body_acc = np.hstack([row[\"S_LIN_ACC_X\"], row[\"S_LIN_ACC_Y\"], row[\"S_LIN_ACC_Z\"]]).astype(float)\n",
    "    r = R.from_quat(np.hstack([row[\"pure_imu_Q_X\"], row[\"pure_imu_Q_Y\"], row[\"pure_imu_Q_Z\"], row[\"pure_imu_Q_W\"]]))\n",
    "    world_acc = r.apply(body_acc)\n",
    "    return world_acc - np.array([0, 0, -9.81])\n",
    "\n",
    "# Convert imu linear acceleration from body frame to world frame\n",
    "train_data[\"S_LIN_ACC_X_world\"] = train_data.apply(lambda row : convert_body_to_world(row)[0], axis = 1)\n",
    "train_data[\"S_LIN_ACC_Y_world\"] = train_data.apply(lambda row : convert_body_to_world(row)[1], axis = 1)\n",
    "train_data[\"S_LIN_ACC_Z_world\"] = train_data.apply(lambda row : convert_body_to_world(row)[2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "plt.figure(figsize=(8,6))\n",
    "t = train_data[\"seconds\"]\n",
    "vel_x = integrate.cumtrapz(train_data[\"S_LIN_ACC_X_world\"], t, initial=0)\n",
    "vel_y = integrate.cumtrapz(train_data[\"S_LIN_ACC_Y_world\"], t, initial=0)\n",
    "vel_z = integrate.cumtrapz(train_data[\"S_LIN_ACC_Z_world\"], t, initial=0) \n",
    "plt.plot(t,signal.detrend(vel_x), label = \"vel_x_detrended\")\n",
    "plt.plot(t,signal.detrend(vel_y), label = \"vel_y_detrended\")\n",
    "plt.plot(t,signal.detrend(vel_z), label = \"vel_z_detrended\",color=\"black\")\n",
    "# plt.plot(t,vel_x, label = \"vel_x\")\n",
    "# plt.plot(t,vel_y, label = \"vel_y\")\n",
    "# plt.plot(t,vel_z, label = \"vel_z\")\n",
    "plt.plot(t,train_data[\"LIN_VEL_X\"], label = \"gt_vel_x\")\n",
    "plt.plot(t,train_data[\"LIN_VEL_Y\"], label = \"gt_vel_y\")\n",
    "plt.plot(t,train_data[\"LIN_VEL_Z\"], label = \"gt_vel_z\")\n",
    "plt.title(\"Velocity integrated from acceleration\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (m/s)\")\n",
    "# plt.xlim([50, 160])\n",
    "# plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check drift error if naive double integration was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_x = signal.detrend(vel_x)\n",
    "vel_y = signal.detrend(vel_y)\n",
    "vel_z = signal.detrend(vel_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement = integrate.cumtrapz(vel_x, t, initial=0)\n",
    "plt.figure()\n",
    "plt.plot(displacement + train_data[\"POS_X\"], label = \"double integrate\")\n",
    "plt.plot(train_data[\"noisy_POS_X\"], label = \"noisy_POS_X\")\n",
    "plt.plot(train_data[\"POS_X\"], label = \"POS_X\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "displacement = integrate.cumtrapz(vel_y, t, initial=0)\n",
    "plt.plot(displacement + train_data[\"POS_Y\"], label = \"double integrate\")\n",
    "plt.plot(train_data[\"noisy_POS_Y\"], label = \"noisy_POS_Y\")\n",
    "plt.plot(train_data[\"POS_Y\"], label = \"POS_Y\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "displacement = integrate.cumtrapz(vel_z, t, initial=0)\n",
    "plt.plot(displacement + train_data[\"POS_Z\"], label = \"double integrate\")\n",
    "plt.plot(train_data[\"noisy_POS_Z\"], label = \"noisy_POS_Z\")\n",
    "plt.plot(train_data[\"POS_Z\"], label = \"POS_Z\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get imu linear velocity integrated using imu acceleration corrected using noisy orientation\n",
    "train_data[\"S_LIN_VEL_X\"] = vel_x\n",
    "train_data[\"S_LIN_VEL_Y\"] = vel_y\n",
    "train_data[\"S_LIN_VEL_Z\"] = vel_z\n",
    "train_data[\"prev_S_LIN_VEL_X\"] = train_data[\"S_LIN_VEL_X\"].shift(1)\n",
    "train_data[\"prev_S_LIN_VEL_Y\"] = train_data[\"S_LIN_VEL_Y\"].shift(1)\n",
    "train_data[\"prev_S_LIN_VEL_Z\"] = train_data[\"S_LIN_VEL_Z\"].shift(1)\n",
    "\n",
    "train_data[\"S_LIN_ACC_X\"] = train_data[\"S_LIN_ACC_X_world\"]\n",
    "train_data[\"S_LIN_ACC_Y\"] = train_data[\"S_LIN_ACC_Y_world\"]\n",
    "train_data[\"S_LIN_ACC_Z\"] = train_data[\"S_LIN_ACC_Z_world\"]\n",
    "train_data[\"prev_S_LIN_ACC_X\"] = train_data[\"S_LIN_ACC_X\"].shift(1)\n",
    "train_data[\"prev_S_LIN_ACC_Y\"] = train_data[\"S_LIN_ACC_Y\"].shift(1)\n",
    "train_data[\"prev_S_LIN_ACC_Z\"] = train_data[\"S_LIN_ACC_Z\"].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining IMU derived Relative translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 10\n",
    "# number of imu readings for each image frame (e.g. if 100Hz IMU and 10Hz Img freq,\n",
    "# there are 10 imu readings for each image frame)\n",
    "image_frame_step = 10 \n",
    "# Gap between frames used in sample (rmb to change the value in \n",
    "# MapNet.ini as well, skip = k/image_frame_step = 10)\n",
    "k  = skip * image_frame_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just using COLMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(k, len(train_data), image_frame_step):\n",
    "    x = train_data.iloc[i, :].noisy_POS_X - train_data.iloc[i - k, :].noisy_POS_X\n",
    "    y = train_data.iloc[i, :].noisy_POS_Y - train_data.iloc[i - k, :].noisy_POS_Y\n",
    "    z = train_data.iloc[i, :].noisy_POS_Z - train_data.iloc[i - k, :].noisy_POS_Z\n",
    "\n",
    "    results.append([x, y, z])\n",
    "\n",
    "noisy_rel_trans = pd.DataFrame(results, columns=[\"rel_POS_X\", \"rel_POS_Y\",\"rel_POS_Z\"])\n",
    "noisy_rel_trans[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "noisy_rel_trans.set_index(\"idx\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "timesteps = []\n",
    "for i in range(k, len(train_data), image_frame_step):\n",
    "    x = y = z = 0\n",
    "    timestep = 0 \n",
    "    for j in range(i - k + 1, i + 1):\n",
    "        row = train_data.iloc[j, :]\n",
    "        x += row.prev_S_LIN_VEL_X * row.timestep + 1/2 * row.prev_S_LIN_ACC_X * row.timestep ** 2 \n",
    "        y += row.prev_S_LIN_VEL_Y * row.timestep + 1/2 * row.prev_S_LIN_ACC_Y * row.timestep ** 2 \n",
    "        z += row.prev_S_LIN_VEL_Z * row.timestep + 1/2 * row.prev_S_LIN_ACC_Z * row.timestep ** 2\n",
    "        timestep += row.timestep\n",
    "    timesteps.append(timestep)\n",
    "    results.append([x, y, z])\n",
    "\n",
    "imu_rel_trans = pd.DataFrame(results, columns=[\"imu_rel_POS_X\", \"imu_rel_POS_Y\",\"imu_rel_POS_Z\"])\n",
    "imu_rel_trans[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "imu_rel_trans.set_index(\"idx\", inplace=True)\n",
    "print(np.mean(timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True relative translation\n",
    "train_data[\"rel_POS_X\"] = train_data[\"POS_X\"] - train_data[\"POS_X\"].shift(k)\n",
    "train_data[\"rel_POS_Y\"] = train_data[\"POS_Y\"] - train_data[\"POS_Y\"].shift(k)\n",
    "train_data[\"rel_POS_Z\"] = train_data[\"POS_Z\"] - train_data[\"POS_Z\"].shift(k)\n",
    "\n",
    "print(\"Just COLMAP\")\n",
    "err =[]\n",
    "for i in range(len(noisy_rel_trans)):\n",
    "    err.append(np.linalg.norm(np.array(noisy_rel_trans[[\"rel_POS_X\", \"rel_POS_Y\",\"rel_POS_Z\"]].iloc[i,:]) - np.array(train_data[[\"rel_POS_X\", \"rel_POS_Y\", \"rel_POS_Z\"]].iloc[k + i * image_frame_step,:])))\n",
    "print(f'Translation error {np.median(err)} (median) m, {np.mean(err)} (mean) m')\n",
    "\n",
    "print(\"Just IMU\")\n",
    "err =[]\n",
    "for i in range(len(imu_rel_trans)):\n",
    "    err.append(np.linalg.norm(np.array(imu_rel_trans[[\"imu_rel_POS_X\", \"imu_rel_POS_Y\",\"imu_rel_POS_Z\"]].iloc[i,:]) - np.array(train_data[[\"rel_POS_X\", \"rel_POS_Y\", \"rel_POS_Z\"]].iloc[k + i * image_frame_step,:])))\n",
    "print(f'Translation error {np.median(err)} (median) m, {np.mean(err)} (mean) m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"imu_rel_POS_X\"] = imu_rel_trans[\"imu_rel_POS_X\"]\n",
    "train_data[\"imu_rel_POS_Y\"] = imu_rel_trans[\"imu_rel_POS_Y\"]\n",
    "train_data[\"imu_rel_POS_Z\"] = imu_rel_trans[\"imu_rel_POS_Z\"]\n",
    "train_data[\"imu_POS_X\"] = train_data[\"noisy_POS_X\"].shift(k) + train_data[\"imu_rel_POS_X\"]\n",
    "train_data[\"imu_POS_Y\"] = train_data[\"noisy_POS_Y\"].shift(k) + train_data[\"imu_rel_POS_Y\"]\n",
    "train_data[\"imu_POS_Z\"] = train_data[\"noisy_POS_Z\"].shift(k) + train_data[\"imu_rel_POS_Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain IMU derived Relative Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get previous angular velocity\n",
    "train_data[\"prev_S_ANG_VEL_X\"] = train_data[\"S_ANG_VEL_X\"].shift(1)\n",
    "train_data[\"prev_S_ANG_VEL_Y\"] = train_data[\"S_ANG_VEL_Y\"].shift(1)\n",
    "train_data[\"prev_S_ANG_VEL_Z\"] = train_data[\"S_ANG_VEL_Z\"].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHRS Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ahrs.filters import AngularRate\n",
    "abs_results = []\n",
    "rel_results = []\n",
    "for i in range(k, len(train_data), image_frame_step):\n",
    "    qw = train_data.iloc[i - k, :].noisy_Q_W\n",
    "    qx = train_data.iloc[i - k, :].noisy_Q_X\n",
    "    qy = train_data.iloc[i - k, :].noisy_Q_Y\n",
    "    qz = train_data.iloc[i - k, :].noisy_Q_Z\n",
    "    q_prev = np.array([qw, qx, qy, qz])\n",
    "    cur_q = q_prev\n",
    "    angular_rate = AngularRate()\n",
    "    for j in range(i - k + 1, i + 1):\n",
    "        row = train_data.iloc[j, :]\n",
    "        cur_q = angular_rate.update(cur_q, \n",
    "                                    np.hstack([row[\"prev_S_ANG_VEL_X\"],\n",
    "                                               row[\"prev_S_ANG_VEL_Y\"], \n",
    "                                               row[\"prev_S_ANG_VEL_Z\"]]),\n",
    "                                    'closed', \n",
    "                                    1,\n",
    "                                    row['timestep'])\n",
    "        cur_q = rowan.normalize(cur_q)\n",
    "    rel_q = calc_rel_orientation(q_prev, cur_q)\n",
    "    abs_results.append(cur_q)\n",
    "    rel_results.append(rel_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_q_ahrs = pd.DataFrame(abs_results, columns=[\"imu_Q_W\", \"imu_Q_X\", \"imu_Q_Y\", \"imu_Q_Z\"])\n",
    "imu_q_ahrs[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "imu_q_ahrs.set_index(\"idx\", inplace=True)\n",
    "\n",
    "imu_q_ahrs_rel = pd.DataFrame(rel_results, columns=[\"imu_rel_Q_W\", \"imu_rel_Q_X\", \"imu_rel_Q_Y\", \"imu_rel_Q_Z\"])\n",
    "imu_q_ahrs_rel[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "imu_q_ahrs_rel.set_index(\"idx\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just COLMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(k, len(train_data), image_frame_step):\n",
    "    qw = train_data.iloc[i - k, :].noisy_Q_W\n",
    "    qx = train_data.iloc[i - k, :].noisy_Q_X\n",
    "    qy = train_data.iloc[i - k, :].noisy_Q_X\n",
    "    qz = train_data.iloc[i - k, :].noisy_Q_Z\n",
    "    q_prev = np.array([qw, qx, qy, qz])\n",
    "    qw = train_data.iloc[i, :].noisy_Q_W\n",
    "    qx = train_data.iloc[i, :].noisy_Q_X\n",
    "    qy = train_data.iloc[i, :].noisy_Q_X\n",
    "    qz = train_data.iloc[i, :].noisy_Q_Z\n",
    "    q = np.array([qw, qx, qy, qz]) \n",
    "    \n",
    "    results.append(calc_rel_orientation(q_prev, q))\n",
    "noisy_orient_rel = pd.DataFrame(results, columns=[\"rel_Q_W\", \"rel_Q_X\", \"rel_Q_Y\", \"rel_Q_Z\"])\n",
    "noisy_orient_rel[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "noisy_orient_rel.set_index(\"idx\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Relative orientation\n",
    "true_rel_orientation = []\n",
    "for i in range(k, len(train_data), image_frame_step):\n",
    "    qw = train_data.iloc[i - k, :].Q_W\n",
    "    qx = train_data.iloc[i - k, :].Q_X\n",
    "    qy = train_data.iloc[i - k, :].Q_X\n",
    "    qz = train_data.iloc[i - k, :].Q_Z\n",
    "    q_prev = np.array([qw, qx, qy, qz])\n",
    "    qw = train_data.iloc[i, :].Q_W\n",
    "    qx = train_data.iloc[i, :].Q_X\n",
    "    qy = train_data.iloc[i, :].Q_X\n",
    "    qz = train_data.iloc[i, :].Q_Z\n",
    "    q = np.array([qw, qx, qy, qz]) \n",
    "    \n",
    "    true_rel_orientation.append(calc_rel_orientation(q_prev, q))\n",
    "true_rel = pd.DataFrame(true_rel_orientation, columns=[\"true_rel_Q_W\", \"true_rel_Q_X\", \"true_rel_Q_Y\", \"true_rel_Q_Z\"])\n",
    "true_rel[\"idx\"] = [i for i in range(k, len(train_data), image_frame_step)]\n",
    "true_rel.set_index(\"idx\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Just COLMAP\")\n",
    "axis_angle_err =[]\n",
    "for i in range(len(imu_q_ahrs_rel)):\n",
    "    axis_angle_err.append(\n",
    "        calc_quat_angle_error_single(noisy_orient_rel[[\"rel_Q_W\", \"rel_Q_X\", \"rel_Q_Y\", \"rel_Q_Z\"]].iloc[i,:],\n",
    "                                    true_rel[[\"true_rel_Q_W\", \"true_rel_Q_X\", \"true_rel_Q_Y\", \"true_rel_Q_Z\"]].iloc[i,:])\n",
    "    )\n",
    "print(f'Orientation error {np.median(axis_angle_err)} (median) deg, {np.mean(axis_angle_err)} (mean) deg')\n",
    "\n",
    "print(\"AHRS\")\n",
    "axis_angle_err =[]\n",
    "for i in range(len(imu_q_ahrs_rel)):\n",
    "    axis_angle_err.append(\n",
    "        calc_quat_angle_error_single(imu_q_ahrs_rel[[\"imu_rel_Q_W\", \"imu_rel_Q_X\", \"imu_rel_Q_Y\", \"imu_rel_Q_Z\"]].iloc[i,:],\n",
    "                                    true_rel[[\"true_rel_Q_W\", \"true_rel_Q_X\", \"true_rel_Q_Y\", \"true_rel_Q_Z\"]].iloc[i,:])\n",
    "    )\n",
    "print(f'Orientation error {np.median(axis_angle_err)} (median) deg, {np.mean(axis_angle_err)} (mean) deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"imu_Q_W\"] = imu_q_ahrs[\"imu_Q_W\"]\n",
    "train_data[\"imu_Q_X\"] = imu_q_ahrs[\"imu_Q_Y\"]\n",
    "train_data[\"imu_Q_Y\"] = imu_q_ahrs[\"imu_Q_X\"]\n",
    "train_data[\"imu_Q_Z\"] = imu_q_ahrs[\"imu_Q_Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of relative poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.hist(imu_rel_trans[\"imu_rel_POS_X\"], label=\"POS_X\", alpha=0.5)\n",
    "plt.hist(imu_rel_trans[\"imu_rel_POS_Y\"], label=\"POS_Y\", alpha=0.5)\n",
    "plt.hist(imu_rel_trans[\"imu_rel_POS_Z\"], label=\"POS_Z\", alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Position Coordinates (m)\")\n",
    "plt.title('Distribution of Train Set Translations ' + r'$\\bf{x}_c$')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(imu_q_ahrs_rel[\"imu_rel_Q_W\"], label=\"Q_W\", alpha=0.5)\n",
    "plt.hist(imu_q_ahrs_rel[\"imu_rel_Q_X\"], label=\"Q_X\", alpha=0.5)\n",
    "plt.hist(imu_q_ahrs_rel[\"imu_rel_Q_Y\"], label=\"Q_Y\", alpha=0.5)\n",
    "plt.hist(imu_q_ahrs_rel[\"imu_rel_Q_Z\"], label=\"Q_Z\", alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Quaternion Values\")\n",
    "plt.title('Distribution of Train Set Orientations ' + r'$\\bf{q}_c$')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_write_file = train_data.iloc[::image_frame_step,:]\n",
    "final_write_file = final_write_file[[\"ImageFile\",\n",
    "                                    \"noisy_POS_X\", \"noisy_POS_Y\", \"noisy_POS_Z\", \"noisy_Q_W\", \"noisy_Q_X\", \"noisy_Q_Y\", \"noisy_Q_Z\",\n",
    "                                    \"imu_POS_X\", \"imu_POS_Y\", \"imu_POS_Z\", \"imu_Q_W\", \"imu_Q_X\",\"imu_Q_Y\",\"imu_Q_Z\"\n",
    "                                    ]]\n",
    "final_write_file.reset_index(drop=True, inplace =True)\n",
    "final_write_file.rename(columns = {'noisy_POS_X':'POS_X', \n",
    "                                   'noisy_POS_Y':'POS_Y',\n",
    "                                   'noisy_POS_Z':'POS_Z',\n",
    "                                   'noisy_Q_W':'Q_W',\n",
    "                                   'noisy_Q_X':'Q_X',\n",
    "                                   'noisy_Q_Y':'Q_Y',\n",
    "                                   'noisy_Q_Z':'Q_Z' }, \n",
    "                        inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_write_file.loc[0:skip-1,'imu_POS_Y'] = final_write_file.loc[0:skip-1,'POS_Y']\n",
    "final_write_file.loc[0:skip-1,'imu_POS_Z'] = final_write_file.loc[0:skip-1,'POS_Z']\n",
    "final_write_file.loc[0:skip-1,'imu_POS_X'] = final_write_file.loc[0:skip-1,'POS_X']\n",
    "final_write_file.loc[0:skip-1,'imu_Q_W'] = final_write_file.loc[0:skip-1,'Q_W']\n",
    "final_write_file.loc[0:skip-1,'imu_Q_X'] = final_write_file.loc[0:skip-1,'Q_X']\n",
    "final_write_file.loc[0:skip-1,'imu_Q_Y'] = final_write_file.loc[0:skip-1,'Q_Y']\n",
    "final_write_file.loc[0:skip-1,'imu_Q_Z'] = final_write_file.loc[0:skip-1,'Q_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_write_file.to_csv('D:/Imperial/FYP/captured_data/airsim_drone_mode/building_new/train/check_v2.txt', \n",
    "                        header=True, \n",
    "                        index=None, \n",
    "                        sep=' ', \n",
    "                        mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('imu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e114fece839044a8054c0aaa3bdbd75b217de5939a76fc671a63ad8057104e17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
